model:
  vocab_size: 27
  d_model: 128
  n_heads: 4
  d_ff: 128
  n_layers: 2
  max_len: 128

train:
  experiment_name: "base_model"
  epochs: 3
  lr: 0.001
  batch_size: 4
  save_strategy: "steps"
  save_steps: 1000
